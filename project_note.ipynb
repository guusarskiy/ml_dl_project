{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchmetrics import MeanSquaredError, R2Score\n",
    "import time\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Готовим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>btc_open</th>\n",
       "      <th>btc_high</th>\n",
       "      <th>btc_low</th>\n",
       "      <th>btc_close</th>\n",
       "      <th>btc_volume</th>\n",
       "      <th>btc_rsi</th>\n",
       "      <th>btc_macd</th>\n",
       "      <th>btc_macd_signal</th>\n",
       "      <th>btc_macd_hist</th>\n",
       "      <th>btc_slowK</th>\n",
       "      <th>btc_slowD</th>\n",
       "      <th>btc_atr</th>\n",
       "      <th>eth_open</th>\n",
       "      <th>eth_high</th>\n",
       "      <th>eth_low</th>\n",
       "      <th>eth_close</th>\n",
       "      <th>eth_volume</th>\n",
       "      <th>fear_greed</th>\n",
       "      <th>eth_rsi</th>\n",
       "      <th>eth_macd</th>\n",
       "      <th>eth_macd_signal</th>\n",
       "      <th>eth_macd_hist</th>\n",
       "      <th>eth_slowK</th>\n",
       "      <th>eth_slowD</th>\n",
       "      <th>eth_atr</th>\n",
       "      <th>fed_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29001</th>\n",
       "      <td>2024-10-28 06:00:00</td>\n",
       "      <td>67904.98</td>\n",
       "      <td>67960.84</td>\n",
       "      <td>67796.96</td>\n",
       "      <td>67960.84</td>\n",
       "      <td>2.126584e+07</td>\n",
       "      <td>61.089602</td>\n",
       "      <td>149.857681</td>\n",
       "      <td>161.277091</td>\n",
       "      <td>-11.419409</td>\n",
       "      <td>41.529205</td>\n",
       "      <td>34.515670</td>\n",
       "      <td>248.548729</td>\n",
       "      <td>2486.39</td>\n",
       "      <td>2491.58</td>\n",
       "      <td>2482.21</td>\n",
       "      <td>2491.58</td>\n",
       "      <td>1.699042e+07</td>\n",
       "      <td>72.0</td>\n",
       "      <td>51.240606</td>\n",
       "      <td>1.623511</td>\n",
       "      <td>3.403689</td>\n",
       "      <td>-1.780178</td>\n",
       "      <td>29.590458</td>\n",
       "      <td>24.128223</td>\n",
       "      <td>14.104938</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29002</th>\n",
       "      <td>2024-10-28 07:00:00</td>\n",
       "      <td>67960.84</td>\n",
       "      <td>68687.24</td>\n",
       "      <td>67960.83</td>\n",
       "      <td>68422.86</td>\n",
       "      <td>6.663986e+07</td>\n",
       "      <td>70.811992</td>\n",
       "      <td>187.464076</td>\n",
       "      <td>166.514488</td>\n",
       "      <td>20.949588</td>\n",
       "      <td>58.815671</td>\n",
       "      <td>43.949671</td>\n",
       "      <td>282.681677</td>\n",
       "      <td>2491.58</td>\n",
       "      <td>2527.35</td>\n",
       "      <td>2490.85</td>\n",
       "      <td>2511.61</td>\n",
       "      <td>3.303710e+07</td>\n",
       "      <td>72.0</td>\n",
       "      <td>60.837478</td>\n",
       "      <td>3.122860</td>\n",
       "      <td>3.347523</td>\n",
       "      <td>-0.224663</td>\n",
       "      <td>44.538457</td>\n",
       "      <td>31.799753</td>\n",
       "      <td>15.704585</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29003</th>\n",
       "      <td>2024-10-28 08:00:00</td>\n",
       "      <td>68422.86</td>\n",
       "      <td>68601.25</td>\n",
       "      <td>68319.72</td>\n",
       "      <td>68319.73</td>\n",
       "      <td>4.146691e+07</td>\n",
       "      <td>66.799715</td>\n",
       "      <td>206.564537</td>\n",
       "      <td>174.524498</td>\n",
       "      <td>32.040040</td>\n",
       "      <td>65.985977</td>\n",
       "      <td>55.443618</td>\n",
       "      <td>282.599414</td>\n",
       "      <td>2511.61</td>\n",
       "      <td>2521.34</td>\n",
       "      <td>2509.44</td>\n",
       "      <td>2513.00</td>\n",
       "      <td>1.957421e+07</td>\n",
       "      <td>72.0</td>\n",
       "      <td>61.405178</td>\n",
       "      <td>4.372858</td>\n",
       "      <td>3.552590</td>\n",
       "      <td>0.820268</td>\n",
       "      <td>60.173923</td>\n",
       "      <td>44.767613</td>\n",
       "      <td>15.432829</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29004</th>\n",
       "      <td>2024-10-28 09:00:00</td>\n",
       "      <td>68319.73</td>\n",
       "      <td>68613.46</td>\n",
       "      <td>68234.50</td>\n",
       "      <td>68567.38</td>\n",
       "      <td>3.743416e+07</td>\n",
       "      <td>71.042774</td>\n",
       "      <td>238.930830</td>\n",
       "      <td>187.405764</td>\n",
       "      <td>51.525066</td>\n",
       "      <td>77.894878</td>\n",
       "      <td>67.565509</td>\n",
       "      <td>289.482313</td>\n",
       "      <td>2513.00</td>\n",
       "      <td>2542.71</td>\n",
       "      <td>2505.25</td>\n",
       "      <td>2542.04</td>\n",
       "      <td>2.804183e+07</td>\n",
       "      <td>72.0</td>\n",
       "      <td>70.897049</td>\n",
       "      <td>7.618949</td>\n",
       "      <td>4.365862</td>\n",
       "      <td>3.253087</td>\n",
       "      <td>81.255087</td>\n",
       "      <td>61.989156</td>\n",
       "      <td>17.006198</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29005</th>\n",
       "      <td>2024-10-28 10:00:00</td>\n",
       "      <td>68567.38</td>\n",
       "      <td>68840.35</td>\n",
       "      <td>68540.79</td>\n",
       "      <td>68626.36</td>\n",
       "      <td>4.522336e+07</td>\n",
       "      <td>71.961822</td>\n",
       "      <td>266.271136</td>\n",
       "      <td>203.178838</td>\n",
       "      <td>63.092297</td>\n",
       "      <td>79.783399</td>\n",
       "      <td>74.554751</td>\n",
       "      <td>290.202148</td>\n",
       "      <td>2542.04</td>\n",
       "      <td>2545.04</td>\n",
       "      <td>2529.26</td>\n",
       "      <td>2531.14</td>\n",
       "      <td>2.580878e+07</td>\n",
       "      <td>72.0</td>\n",
       "      <td>64.486353</td>\n",
       "      <td>9.205842</td>\n",
       "      <td>5.333858</td>\n",
       "      <td>3.871984</td>\n",
       "      <td>84.599693</td>\n",
       "      <td>75.342901</td>\n",
       "      <td>16.918613</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 timestamp  btc_open  btc_high   btc_low  btc_close  \\\n",
       "29001  2024-10-28 06:00:00  67904.98  67960.84  67796.96   67960.84   \n",
       "29002  2024-10-28 07:00:00  67960.84  68687.24  67960.83   68422.86   \n",
       "29003  2024-10-28 08:00:00  68422.86  68601.25  68319.72   68319.73   \n",
       "29004  2024-10-28 09:00:00  68319.73  68613.46  68234.50   68567.38   \n",
       "29005  2024-10-28 10:00:00  68567.38  68840.35  68540.79   68626.36   \n",
       "\n",
       "         btc_volume    btc_rsi    btc_macd  btc_macd_signal  btc_macd_hist  \\\n",
       "29001  2.126584e+07  61.089602  149.857681       161.277091     -11.419409   \n",
       "29002  6.663986e+07  70.811992  187.464076       166.514488      20.949588   \n",
       "29003  4.146691e+07  66.799715  206.564537       174.524498      32.040040   \n",
       "29004  3.743416e+07  71.042774  238.930830       187.405764      51.525066   \n",
       "29005  4.522336e+07  71.961822  266.271136       203.178838      63.092297   \n",
       "\n",
       "       btc_slowK  btc_slowD     btc_atr  eth_open  eth_high  eth_low  \\\n",
       "29001  41.529205  34.515670  248.548729   2486.39   2491.58  2482.21   \n",
       "29002  58.815671  43.949671  282.681677   2491.58   2527.35  2490.85   \n",
       "29003  65.985977  55.443618  282.599414   2511.61   2521.34  2509.44   \n",
       "29004  77.894878  67.565509  289.482313   2513.00   2542.71  2505.25   \n",
       "29005  79.783399  74.554751  290.202148   2542.04   2545.04  2529.26   \n",
       "\n",
       "       eth_close    eth_volume  fear_greed    eth_rsi  eth_macd  \\\n",
       "29001    2491.58  1.699042e+07        72.0  51.240606  1.623511   \n",
       "29002    2511.61  3.303710e+07        72.0  60.837478  3.122860   \n",
       "29003    2513.00  1.957421e+07        72.0  61.405178  4.372858   \n",
       "29004    2542.04  2.804183e+07        72.0  70.897049  7.618949   \n",
       "29005    2531.14  2.580878e+07        72.0  64.486353  9.205842   \n",
       "\n",
       "       eth_macd_signal  eth_macd_hist  eth_slowK  eth_slowD    eth_atr  \\\n",
       "29001         3.403689      -1.780178  29.590458  24.128223  14.104938   \n",
       "29002         3.347523      -0.224663  44.538457  31.799753  15.704585   \n",
       "29003         3.552590       0.820268  60.173923  44.767613  15.432829   \n",
       "29004         4.365862       3.253087  81.255087  61.989156  17.006198   \n",
       "29005         5.333858       3.871984  84.599693  75.342901  16.918613   \n",
       "\n",
       "       fed_rate  \n",
       "29001      4.83  \n",
       "29002      4.83  \n",
       "29003      4.83  \n",
       "29004      4.83  \n",
       "29005      4.83  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_data = pd.read_csv('C:/Projects/vsCode/ml_unik_project/data/market_project_data_usd.csv', sep=',')\n",
    "market_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29006 entries, 0 to 29005\n",
      "Data columns (total 27 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   timestamp        29006 non-null  object \n",
      " 1   btc_open         29006 non-null  float64\n",
      " 2   btc_high         29006 non-null  float64\n",
      " 3   btc_low          29006 non-null  float64\n",
      " 4   btc_close        29006 non-null  float64\n",
      " 5   btc_volume       29006 non-null  float64\n",
      " 6   btc_rsi          29006 non-null  float64\n",
      " 7   btc_macd         29006 non-null  float64\n",
      " 8   btc_macd_signal  29006 non-null  float64\n",
      " 9   btc_macd_hist    29006 non-null  float64\n",
      " 10  btc_slowK        29006 non-null  float64\n",
      " 11  btc_slowD        29006 non-null  float64\n",
      " 12  btc_atr          29006 non-null  float64\n",
      " 13  eth_open         29006 non-null  float64\n",
      " 14  eth_high         29006 non-null  float64\n",
      " 15  eth_low          29006 non-null  float64\n",
      " 16  eth_close        29006 non-null  float64\n",
      " 17  eth_volume       29006 non-null  float64\n",
      " 18  fear_greed       29006 non-null  float64\n",
      " 19  eth_rsi          29006 non-null  float64\n",
      " 20  eth_macd         29006 non-null  float64\n",
      " 21  eth_macd_signal  29006 non-null  float64\n",
      " 22  eth_macd_hist    29006 non-null  float64\n",
      " 23  eth_slowK        29006 non-null  float64\n",
      " 24  eth_slowD        29006 non-null  float64\n",
      " 25  eth_atr          29006 non-null  float64\n",
      " 26  fed_rate         29006 non-null  float64\n",
      "dtypes: float64(26), object(1)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "market_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Можем удалить timestamp, т.к. данные уже отсортированы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29006 entries, 0 to 29005\n",
      "Data columns (total 26 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   btc_open         29006 non-null  float64\n",
      " 1   btc_high         29006 non-null  float64\n",
      " 2   btc_low          29006 non-null  float64\n",
      " 3   btc_close        29006 non-null  float64\n",
      " 4   btc_volume       29006 non-null  float64\n",
      " 5   btc_rsi          29006 non-null  float64\n",
      " 6   btc_macd         29006 non-null  float64\n",
      " 7   btc_macd_signal  29006 non-null  float64\n",
      " 8   btc_macd_hist    29006 non-null  float64\n",
      " 9   btc_slowK        29006 non-null  float64\n",
      " 10  btc_slowD        29006 non-null  float64\n",
      " 11  btc_atr          29006 non-null  float64\n",
      " 12  eth_open         29006 non-null  float64\n",
      " 13  eth_high         29006 non-null  float64\n",
      " 14  eth_low          29006 non-null  float64\n",
      " 15  eth_close        29006 non-null  float64\n",
      " 16  eth_volume       29006 non-null  float64\n",
      " 17  fear_greed       29006 non-null  float64\n",
      " 18  eth_rsi          29006 non-null  float64\n",
      " 19  eth_macd         29006 non-null  float64\n",
      " 20  eth_macd_signal  29006 non-null  float64\n",
      " 21  eth_macd_hist    29006 non-null  float64\n",
      " 22  eth_slowK        29006 non-null  float64\n",
      " 23  eth_slowD        29006 non-null  float64\n",
      " 24  eth_atr          29006 non-null  float64\n",
      " 25  fed_rate         29006 non-null  float64\n",
      "dtypes: float64(26)\n",
      "memory usage: 5.8 MB\n"
     ]
    }
   ],
   "source": [
    "market_data = market_data.drop(['timestamp'], axis=1)\n",
    "market_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train | validaton | test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train df:  (20304, 26)\n",
      "size of valid df:  (4350, 26)\n",
      "size of test df:  (4352, 26)\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.7 * len(market_data))\n",
    "valid_size = int(0.15 * len(market_data))\n",
    "test_size = len(market_data) - train_size - valid_size\n",
    "\n",
    "train_data = market_data[:train_size]\n",
    "valid_data = market_data[train_size : train_size + valid_size]\n",
    "test_data = market_data[train_size + valid_size:]\n",
    "\n",
    "print('size of train df: ', train_data.shape)\n",
    "print('size of valid df: ', valid_data.shape)\n",
    "print('size of test df: ', test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Нормализация MixMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = 'btc_close'\n",
    "X_cols = [col for col in train_data.columns if col != y_col]\n",
    "\n",
    "train_data = train_data.copy()\n",
    "valid_data = valid_data.copy()\n",
    "test_data = test_data.copy()\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "train_data[X_cols] = scaler_X.fit_transform(train_data[X_cols])\n",
    "train_data[y_col] = scaler_y.fit_transform(train_data[[y_col]])\n",
    "\n",
    "valid_data[X_cols] = scaler_X.transform(valid_data[X_cols])\n",
    "valid_data[y_col] = scaler_y.transform(valid_data[[y_col]])\n",
    "\n",
    "test_data[X_cols] = scaler_X.transform(test_data[X_cols])\n",
    "test_data[y_col] = scaler_y.transform(test_data[[y_col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>btc_open</th>\n",
       "      <th>btc_high</th>\n",
       "      <th>btc_low</th>\n",
       "      <th>btc_close</th>\n",
       "      <th>btc_volume</th>\n",
       "      <th>btc_rsi</th>\n",
       "      <th>btc_macd</th>\n",
       "      <th>btc_macd_signal</th>\n",
       "      <th>btc_macd_hist</th>\n",
       "      <th>btc_slowK</th>\n",
       "      <th>btc_slowD</th>\n",
       "      <th>btc_atr</th>\n",
       "      <th>eth_open</th>\n",
       "      <th>eth_high</th>\n",
       "      <th>eth_low</th>\n",
       "      <th>eth_close</th>\n",
       "      <th>eth_volume</th>\n",
       "      <th>fear_greed</th>\n",
       "      <th>eth_rsi</th>\n",
       "      <th>eth_macd</th>\n",
       "      <th>eth_macd_signal</th>\n",
       "      <th>eth_macd_hist</th>\n",
       "      <th>eth_slowK</th>\n",
       "      <th>eth_slowD</th>\n",
       "      <th>eth_atr</th>\n",
       "      <th>fed_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29001</th>\n",
       "      <td>0.987301</td>\n",
       "      <td>0.981082</td>\n",
       "      <td>0.987947</td>\n",
       "      <td>0.988357</td>\n",
       "      <td>0.077967</td>\n",
       "      <td>0.641721</td>\n",
       "      <td>0.689794</td>\n",
       "      <td>0.692881</td>\n",
       "      <td>0.598078</td>\n",
       "      <td>0.403437</td>\n",
       "      <td>0.337257</td>\n",
       "      <td>0.166073</td>\n",
       "      <td>0.401363</td>\n",
       "      <td>0.397379</td>\n",
       "      <td>0.405253</td>\n",
       "      <td>0.402680</td>\n",
       "      <td>0.135176</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.526295</td>\n",
       "      <td>0.619930</td>\n",
       "      <td>0.631782</td>\n",
       "      <td>0.604254</td>\n",
       "      <td>0.278552</td>\n",
       "      <td>0.215435</td>\n",
       "      <td>0.111974</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29002</th>\n",
       "      <td>0.988357</td>\n",
       "      <td>0.994737</td>\n",
       "      <td>0.991042</td>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.244330</td>\n",
       "      <td>0.753902</td>\n",
       "      <td>0.700216</td>\n",
       "      <td>0.694515</td>\n",
       "      <td>0.626393</td>\n",
       "      <td>0.580578</td>\n",
       "      <td>0.436954</td>\n",
       "      <td>0.190260</td>\n",
       "      <td>0.402680</td>\n",
       "      <td>0.406466</td>\n",
       "      <td>0.407440</td>\n",
       "      <td>0.407762</td>\n",
       "      <td>0.262843</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.636032</td>\n",
       "      <td>0.625948</td>\n",
       "      <td>0.631533</td>\n",
       "      <td>0.619878</td>\n",
       "      <td>0.432272</td>\n",
       "      <td>0.295510</td>\n",
       "      <td>0.126300</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29003</th>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.993121</td>\n",
       "      <td>0.997819</td>\n",
       "      <td>0.995139</td>\n",
       "      <td>0.152034</td>\n",
       "      <td>0.707606</td>\n",
       "      <td>0.705509</td>\n",
       "      <td>0.697014</td>\n",
       "      <td>0.636095</td>\n",
       "      <td>0.654055</td>\n",
       "      <td>0.558421</td>\n",
       "      <td>0.190201</td>\n",
       "      <td>0.407762</td>\n",
       "      <td>0.404939</td>\n",
       "      <td>0.412144</td>\n",
       "      <td>0.408114</td>\n",
       "      <td>0.155732</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.642523</td>\n",
       "      <td>0.630965</td>\n",
       "      <td>0.632444</td>\n",
       "      <td>0.630373</td>\n",
       "      <td>0.593061</td>\n",
       "      <td>0.430866</td>\n",
       "      <td>0.123866</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29004</th>\n",
       "      <td>0.995139</td>\n",
       "      <td>0.993350</td>\n",
       "      <td>0.996210</td>\n",
       "      <td>0.999818</td>\n",
       "      <td>0.137248</td>\n",
       "      <td>0.756564</td>\n",
       "      <td>0.714478</td>\n",
       "      <td>0.701034</td>\n",
       "      <td>0.653140</td>\n",
       "      <td>0.776091</td>\n",
       "      <td>0.686523</td>\n",
       "      <td>0.195079</td>\n",
       "      <td>0.408114</td>\n",
       "      <td>0.410368</td>\n",
       "      <td>0.411084</td>\n",
       "      <td>0.415482</td>\n",
       "      <td>0.223101</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.751060</td>\n",
       "      <td>0.643992</td>\n",
       "      <td>0.636060</td>\n",
       "      <td>0.654808</td>\n",
       "      <td>0.809851</td>\n",
       "      <td>0.610623</td>\n",
       "      <td>0.137956</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29005</th>\n",
       "      <td>0.999818</td>\n",
       "      <td>0.997615</td>\n",
       "      <td>1.001994</td>\n",
       "      <td>1.000933</td>\n",
       "      <td>0.165807</td>\n",
       "      <td>0.767169</td>\n",
       "      <td>0.722055</td>\n",
       "      <td>0.705956</td>\n",
       "      <td>0.663258</td>\n",
       "      <td>0.795443</td>\n",
       "      <td>0.760385</td>\n",
       "      <td>0.195589</td>\n",
       "      <td>0.415482</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>0.417160</td>\n",
       "      <td>0.412717</td>\n",
       "      <td>0.205335</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.677756</td>\n",
       "      <td>0.650361</td>\n",
       "      <td>0.640364</td>\n",
       "      <td>0.661025</td>\n",
       "      <td>0.844246</td>\n",
       "      <td>0.750007</td>\n",
       "      <td>0.137172</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       btc_open  btc_high   btc_low  btc_close  btc_volume   btc_rsi  \\\n",
       "29001  0.987301  0.981082  0.987947   0.988357    0.077967  0.641721   \n",
       "29002  0.988357  0.994737  0.991042   0.997087    0.244330  0.753902   \n",
       "29003  0.997087  0.993121  0.997819   0.995139    0.152034  0.707606   \n",
       "29004  0.995139  0.993350  0.996210   0.999818    0.137248  0.756564   \n",
       "29005  0.999818  0.997615  1.001994   1.000933    0.165807  0.767169   \n",
       "\n",
       "       btc_macd  btc_macd_signal  btc_macd_hist  btc_slowK  btc_slowD  \\\n",
       "29001  0.689794         0.692881       0.598078   0.403437   0.337257   \n",
       "29002  0.700216         0.694515       0.626393   0.580578   0.436954   \n",
       "29003  0.705509         0.697014       0.636095   0.654055   0.558421   \n",
       "29004  0.714478         0.701034       0.653140   0.776091   0.686523   \n",
       "29005  0.722055         0.705956       0.663258   0.795443   0.760385   \n",
       "\n",
       "        btc_atr  eth_open  eth_high   eth_low  eth_close  eth_volume  \\\n",
       "29001  0.166073  0.401363  0.397379  0.405253   0.402680    0.135176   \n",
       "29002  0.190260  0.402680  0.406466  0.407440   0.407762    0.262843   \n",
       "29003  0.190201  0.407762  0.404939  0.412144   0.408114    0.155732   \n",
       "29004  0.195079  0.408114  0.410368  0.411084   0.415482    0.223101   \n",
       "29005  0.195589  0.415482  0.410959  0.417160   0.412717    0.205335   \n",
       "\n",
       "       fear_greed   eth_rsi  eth_macd  eth_macd_signal  eth_macd_hist  \\\n",
       "29001    0.846154  0.526295  0.619930         0.631782       0.604254   \n",
       "29002    0.846154  0.636032  0.625948         0.631533       0.619878   \n",
       "29003    0.846154  0.642523  0.630965         0.632444       0.630373   \n",
       "29004    0.846154  0.751060  0.643992         0.636060       0.654808   \n",
       "29005    0.846154  0.677756  0.650361         0.640364       0.661025   \n",
       "\n",
       "       eth_slowK  eth_slowD   eth_atr  fed_rate  \n",
       "29001   0.278552   0.215435  0.111974  0.904762  \n",
       "29002   0.432272   0.295510  0.126300  0.904762  \n",
       "29003   0.593061   0.430866  0.123866  0.904762  \n",
       "29004   0.809851   0.610623  0.137956  0.904762  \n",
       "29005   0.844246   0.750007  0.137172  0.904762  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создание временных окон"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, target_column, sequence_length=24):\n",
    "        self.data = data\n",
    "        self.target_column = target_column\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data.iloc[idx:idx + self.sequence_length].drop(columns=[self.target_column]).values\n",
    "        \n",
    "        y = self.data.iloc[idx + self.sequence_length][self.target_column]\n",
    "        \n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([96, 25]), y shape: 0.33579716086387634\n",
      "len train:  20208\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 48\n",
    "target_column = 'btc_close'  \n",
    "\n",
    "train_dataset = TimeSeriesDataset(train_data, target_column, sequence_length)\n",
    "val_dataset = TimeSeriesDataset(valid_data, target_column, sequence_length)\n",
    "test_dataset = TimeSeriesDataset(test_data, target_column, sequence_length)\n",
    "\n",
    "X, y = train_dataset[0]\n",
    "print(f\"X shape: {X.shape}, y shape: {y}\")\n",
    "print(\"len train: \", len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0| shape X: torch.Size([64, 96, 25]), shape y: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
    "    print(f\"batch {batch_idx}| shape X: {x_batch.shape}, shape y: {y_batch.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Строим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#device = \"cpu\"\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, fc_size, output_size, dropout_rate=0.2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        # 1st LSTM\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size1, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # 2nd LSTM\n",
    "        self.lstm2 = nn.LSTM(hidden_size1, hidden_size2, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Linears\n",
    "        self.fc1 = nn.Linear(hidden_size2, fc_size)  \n",
    "        self.sigmoid = nn.Sigmoid()  \n",
    "        self.fc2 = nn.Linear(fc_size, output_size)  \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm1(x)\n",
    "        out = self.dropout1(out)\n",
    "        \n",
    "        out, _ = self.lstm2(out)\n",
    "        out = self.dropout2(out)\n",
    "\n",
    "        out = out[:, -1, :]  \n",
    "        \n",
    "        out = self.fc1(out)  \n",
    "        out = self.sigmoid(out)  \n",
    "        out = self.fc2(out)  \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMModel(\n",
      "  (lstm1): LSTM(25, 512, batch_first=True)\n",
      "  (dropout1): Dropout(p=0.3, inplace=False)\n",
      "  (lstm2): LSTM(512, 256, batch_first=True)\n",
      "  (dropout2): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=256, out_features=32, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = 25   \n",
    "hidden_size1 = 512  \n",
    "hidden_size2 = 256  \n",
    "fc_size = 32      \n",
    "output_size = 1     \n",
    "dropout_rate = 0.3\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size1, hidden_size2, fc_size, output_size, dropout_rate).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "X_example = torch.rand(BATCH_SIZE, sequence_length, input_size).to(device)\n",
    "\n",
    "y_pred = model(X_example)\n",
    "print(f\"output shape: {y_pred.shape}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_nn, train_loader, test_loader, optimizer, loss_fn, num_epochs, device):\n",
    "    train_r2 = R2Score().to(device)\n",
    "    test_r2 = R2Score().to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        train_iters = 0\n",
    "        \n",
    "        model_nn.train()\n",
    "        \n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(device), y.to(device)  \n",
    "            y = y.unsqueeze(-1)  \n",
    "            \n",
    "            y_pred = model_nn(X)  \n",
    "            \n",
    "            optimizer.zero_grad()  \n",
    "            loss = loss_fn(y_pred, y)  \n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "            \n",
    "            train_loss += loss.item()  \n",
    "            train_iters += 1\n",
    "            \n",
    "            train_r2.update(y_pred, y)\n",
    "        \n",
    "        train_r2_out = train_r2.compute()\n",
    "        train_r2.reset()\n",
    "\n",
    "        test_loss = 0.0\n",
    "        test_iters = 0\n",
    "        \n",
    "        model_nn.eval()\n",
    "        \n",
    "        with torch.no_grad():  \n",
    "            for X, y in test_loader:\n",
    "                X, y = X.to(device), y.to(device)  \n",
    "                y = y.unsqueeze(-1)  \n",
    "                \n",
    "                y_pred = model_nn(X)  \n",
    "                \n",
    "                loss = loss_fn(y_pred, y)  \n",
    "                \n",
    "                test_loss += loss.item()  \n",
    "                test_iters += 1\n",
    "                \n",
    "                test_r2.update(y_pred, y)\n",
    "        \n",
    "        test_r2_out = test_r2.compute()\n",
    "        test_r2.reset()\n",
    "\n",
    "        if (epoch < 9):\n",
    "            print(f\"Эпоха: 0{epoch+1} | Время: {time.time()-start:.2f} сек | \"\n",
    "              f\"Train Loss: {train_loss/train_iters:.4f} | Train R²: {train_r2_out*100:.2f}% | \"\n",
    "              f\"Test Loss: {test_loss/test_iters:.4f} | Test R²: {test_r2_out*100:.2f}%\")\n",
    "        else:\n",
    "            print(f\"Эпоха: {epoch+1} | Время: {time.time()-start:.2f} сек | \"\n",
    "                f\"Train Loss: {train_loss/train_iters:.4f} | Train R²: {train_r2_out*100:.2f}% | \"\n",
    "                f\"Test Loss: {test_loss/test_iters:.4f} | Test R²: {test_r2_out*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 01 | Время: 16.28 сек | Train Loss: 0.0106 | Train R²: 79.82% | Test Loss: 0.3696 | Test R²: -6010.51%\n",
      "Эпоха: 02 | Время: 16.73 сек | Train Loss: 0.0072 | Train R²: 86.37% | Test Loss: 0.4399 | Test R²: -7172.35%\n",
      "Эпоха: 03 | Время: 16.25 сек | Train Loss: 0.0090 | Train R²: 82.84% | Test Loss: 0.4672 | Test R²: -7625.66%\n",
      "Эпоха: 04 | Время: 16.56 сек | Train Loss: 0.0097 | Train R²: 81.60% | Test Loss: 0.4706 | Test R²: -7681.20%\n",
      "Эпоха: 05 | Время: 16.41 сек | Train Loss: 0.0099 | Train R²: 81.09% | Test Loss: 0.4719 | Test R²: -7702.72%\n",
      "Эпоха: 06 | Время: 16.49 сек | Train Loss: 0.0101 | Train R²: 80.74% | Test Loss: 0.4722 | Test R²: -7708.56%\n",
      "Эпоха: 07 | Время: 16.37 сек | Train Loss: 0.0102 | Train R²: 80.50% | Test Loss: 0.4725 | Test R²: -7712.48%\n",
      "Эпоха: 08 | Время: 16.46 сек | Train Loss: 0.0103 | Train R²: 80.32% | Test Loss: 0.4726 | Test R²: -7714.92%\n",
      "Эпоха: 09 | Время: 16.30 сек | Train Loss: 0.0104 | Train R²: 80.20% | Test Loss: 0.4728 | Test R²: -7717.37%\n",
      "Эпоха: 10 | Время: 16.73 сек | Train Loss: 0.0105 | Train R²: 80.10% | Test Loss: 0.4728 | Test R²: -7717.97%\n",
      "Эпоха: 11 | Время: 16.83 сек | Train Loss: 0.0105 | Train R²: 80.02% | Test Loss: 0.4728 | Test R²: -7717.97%\n",
      "Эпоха: 12 | Время: 16.98 сек | Train Loss: 0.0105 | Train R²: 79.96% | Test Loss: 0.4729 | Test R²: -7719.99%\n",
      "Эпоха: 13 | Время: 16.50 сек | Train Loss: 0.0106 | Train R²: 79.91% | Test Loss: 0.4729 | Test R²: -7719.97%\n",
      "Эпоха: 14 | Время: 16.52 сек | Train Loss: 0.0106 | Train R²: 79.87% | Test Loss: 0.4729 | Test R²: -7720.14%\n",
      "Эпоха: 15 | Время: 15.71 сек | Train Loss: 0.0106 | Train R²: 79.84% | Test Loss: 0.4730 | Test R²: -7720.55%\n",
      "Эпоха: 16 | Время: 16.63 сек | Train Loss: 0.0106 | Train R²: 79.81% | Test Loss: 0.4730 | Test R²: -7720.56%\n",
      "Эпоха: 17 | Время: 16.33 сек | Train Loss: 0.0106 | Train R²: 79.79% | Test Loss: 0.4730 | Test R²: -7720.75%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[238], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[237], line 38\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model_nn, train_loader, test_loader, optimizer, loss_fn, num_epochs, device)\u001b[0m\n\u001b[0;32m     35\u001b[0m model_nn\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \n\u001b[1;32m---> 38\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kosar\\anaconda3\\envs\\ml_unik_project\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\kosar\\anaconda3\\envs\\ml_unik_project\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\kosar\\anaconda3\\envs\\ml_unik_project\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[229], line 15\u001b[0m, in \u001b[0;36mTimeSeriesDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     11\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[idx:idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence_length]\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_column])\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     13\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence_length][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_column]\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m, torch\u001b[38;5;241m.\u001b[39mtensor(y, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, test_loader, optimizer, loss_fn, num_epochs, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_unik_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
